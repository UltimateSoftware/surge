akka {
  actor {
    serializers {
      jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
      jackson-cbor = "akka.serialization.jackson.JacksonCborSerializer"
    }
    serialization-bindings {
      "surge.akka.cluster.JacksonSerializable" = jackson-cbor
    }
  }
}

kafka {
  publisher {
    # The Kafka publisher for a partition batches messages together into transactions for all or nothing guarentees as well as
    # better throughput.  The publisher will flush any received requests to publish state/events on this interval in a single
    # transaction.  Increasing will give better throughput but higher average latency.  It is not recommended to decrease this
    # as Kafka transactions add a small amount of overhead per transaction and a smaller interval would increase the impact of
    # transaction overhead on commits to Kafka.
    flush-interval = 50 ms
    flush-interval = ${?KAFKA_PUBLISHER_FLUSH_INTERVAL}

    transaction-warning-time = 1 second
    transaction-warning-time = ${?KAFKA_PUBLISHER_TRANSACTION_WARNING_TIME}

    batch-size = 16384
    batch-size = ${?KAFKA_PUBLISHER_BATCH_SIZE}

    linger-ms = 5
    linger-ms = ${?KAFKA_PUBLISHER_LINGER_MS}

    compression-type = "lz4"
    compression-type = ${?KAFKA_PUBLISHER_COMPRESSION_TYPE}

    transaction-timeout-ms = 60000
    transaction-timeout-ms = ${?KAFKA_PUBLISHER_TRANSACTION_TIMEOUT_MS}

    ktable-check-interval = 500 milliseconds
    ktable-check-interval = ${?KAFKA_PUBLISHER_INITIALIZATION_INTERVAL}

    init-transactions {
      # The time the producer actor will wait before attempting to re-initialize transactions when the broker returns an authorization exception
      authz-exception-retry-time = 1 minute
      authz-exception-retry-time = ${?KAFKA_PUBLISHER_INIT_TRANSACTIONS_AUTHZ_RETRY_TIME}

      # The time the producer actor will wait before attempting to re-initialize transactions on any exception not already handled by another retry time
      other-exception-retry-time = 3 seconds
      other-exception-retry-time = ${?KAFKA_PUBLISHER_INIT_TRANSACTIONS_RETRY_TIME}
    }
  }
}

# Thread pool used for serializing events & state before they're sent to Kafka
surge {
  serialization {
    thread-pool-size = 32
    thread-pool-size = ${?SURGE_SERIALIZATION_THREAD_POOL_SIZE}
  }

  health {
    bus {
        stream-on-init = false
    }
  }
}

# Separate thread pool for the Kafka publisher actor
kafka-publisher-actor-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 32
  }
  throughput = 1
}
